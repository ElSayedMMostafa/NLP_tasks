{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**University of Science and Technology UST,  Zewail City**<br>\n",
    "**CIE Program**<br>\n",
    "**Natural Language Processing - CIE 555**<br>\n",
    "**Lab Assignment - Fourgrams & Fivegrams models**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student Name:** Elsayed Mohammed Elsayed Mostafa <br>\n",
    "**Student ID:**   201700316"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zAsU-lGrD2yD"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "f = open(\"9053.txt\", \"r\")\n",
    "Dataset = []\n",
    "for line in f:\n",
    "   line = re.sub(r'\\@\\@\\d{8} \\@\\d{7}/','',line)\n",
    "   line = re.sub(r'<h>|<p>','',line)\n",
    "   line = re.sub(r'  ',' ',line)\n",
    "   line = re.sub(r'\\@','',line)\n",
    "   Dataset.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four-grams Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fourgram(string):\n",
    "    #assert len(string) == 4\n",
    "    \"\"\"\"\n",
    "     A function convert a string line to list of fourgrams (each four consecutive words)\n",
    "     @ Parameters:\n",
    "         string: a string of  4 words\n",
    "     @ Returs:\n",
    "         Fourgrams: a list of all the possible four consecutive words\n",
    "         \"\"\"\n",
    "    string = \"<START> \"+ string +\" <END>\"\n",
    "     # Splitting the string into list words\n",
    "    word_list = string.split(' ')\n",
    "    Fourgrams = []\n",
    "     # Fill the Fourgrams list by all the possible four consecutive words\n",
    "    for i in range(len(word_list)-3):\n",
    "        Fourgrams.append([word_list[i],word_list[i+1],word_list[i+2], word_list[i+3]])\n",
    "    return Fourgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_fourgrams(Dataset):\n",
    "    \"\"\"\"\n",
    "     A function that constructs a dictionary for 4-grams. Each key is tuple of 3 entries + \n",
    "     the fourth entry, where the value is the count of this 4-gram/combination \n",
    "     @ Parameters:\n",
    "         dataset: A huge string to construct the 4-grams from.\n",
    "     @ Returns:\n",
    "         Fourgrams_dict: The dictionary holds all the 4-grams combinations with their counts\n",
    "        \"\"\"\n",
    "    Total_Count = 0\n",
    "    # Construct a default dictionary to save the fourgrams\n",
    "    Fourgrams_dict = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    # Loop for each line in the dataset\n",
    "    for line in Dataset:\n",
    "        #line.replace(' ','')\n",
    "        # Convert a string line to list of fourgrams (each four consecutive words)\n",
    "        list_of_grams = Fourgram(line)\n",
    "        Total_Count += len(list_of_grams)\n",
    "        # Fill the fourgrams dictionary with its keys and values\n",
    "        for w1,w2,w3,w4 in list_of_grams:\n",
    "               Fourgrams_dict[(w1, w2, w3)][w4] += 1\n",
    "    #Normailzation             \n",
    "    for w1_w2_w3 in Fourgrams_dict:\n",
    "          for w4 in Fourgrams_dict[w1_w2_w3]:\n",
    "                  Fourgrams_dict[w1_w2_w3][w4] /=  Total_Count\n",
    "        \n",
    "    return Fourgrams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence4(fourgrams,sentence_,first_word, second_word, third_word,iters=0,MAX_ITER=18):\n",
    "    #if third_word == '.':\n",
    "        #return sentence\n",
    "    if iters >= MAX_ITER:\n",
    "        return sentence_\n",
    "    #next_word = max(fourgrams[first_word,second_word,third_word], key=fourgrams[first_word,second_word,third_word].get)\n",
    "    next_word = random.choice(list(fourgrams[first_word,second_word,third_word].keys()))\n",
    "    sentence_.append(next_word)\n",
    "    return generate_sentence4(fourgrams=fourgrams,sentence_=sentence_,first_word = second_word, second_word=third_word, third_word=next_word, iters = iters+1, MAX_ITER=MAX_ITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***For the coming part, we were supposed to start with 'START' keyword; however, for more sensible created sentences, I chose to start with actual words. I prefered that as the keyword 'START' is not repeated with many words hence the variability of sentences would not be high as I need.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadgram TRIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the Quadgrams dictionary using the dataset available.\n",
    "fourgrams = construct_fourgrams(Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct 3 sentences using the quadgram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "even if you cant get back . Its generally better to spend your time working on things that \n",
      "\n",
      "even if you 're promoting in all the wrong places . You have no more insight into what \n",
      "\n",
      "even if you 've perfected your craft at the local level . Newsletters Churches , businesses , neighborhood \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters Definitions..\n",
    "max_iters = 15\n",
    "\n",
    "#Sentence 0\n",
    "sentence = ['even', 'if', 'you']\n",
    "sentence0 = generate_sentence4(fourgrams,sentence,first_word=sentence[0],second_word=sentence[1],third_word=sentence[2],MAX_ITER=max_iters)\n",
    "print(' '.join(sentence0), '\\n')\n",
    "\n",
    "#Sentence 1\n",
    "sentence = ['even', 'if', 'you']\n",
    "sentence1 = generate_sentence4(fourgrams,sentence,first_word=sentence[0],second_word=sentence[1],third_word=sentence[2],MAX_ITER=max_iters)\n",
    "print(' '.join(sentence1), '\\n')\n",
    "\n",
    "#Sentence 2\n",
    "sentence = ['even', 'if', 'you']\n",
    "sentence2 = generate_sentence4(fourgrams,sentence,first_word=sentence[0],second_word=sentence[1],third_word=sentence[2],MAX_ITER=max_iters)\n",
    "print(' '.join(sentence2), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four-grams Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fivegram(string):\n",
    "    \"\"\"\"\n",
    "     A function convert a string line to list of fivegrams (each five consecutive words)\n",
    "     @ Parameters:\n",
    "         string: a string of 5 words\n",
    "     @ Returs:\n",
    "         Fivegrams: a list of all the possible five consecutive words\n",
    "         \"\"\"\n",
    "    string = \"<START> \"+ string +\" <END>\"\n",
    "     # Splitting the string into list words\n",
    "    word_list = string.split(' ')\n",
    "    Fivegrams = []\n",
    "     # Fill the Fourgrams list by all the possible four consecutive words\n",
    "    for i in range(len(word_list)-4):\n",
    "        Fivegrams.append([word_list[i],word_list[i+1],word_list[i+2], word_list[i+3], word_list[i+4]])\n",
    "    return Fivegrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_fivegrams(Dataset):\n",
    "    \"\"\"\"\n",
    "     A function that constructs a dictionary for 5-grams. Each key is tuple of 4 entries + \n",
    "     the fifth entry, where the value is the count of this 5-gram/combination \n",
    "     @ Parameters:\n",
    "         dataset: A huge string to construct the 5-grams from.\n",
    "     @ Returns:\n",
    "         Fivegrams_dict: The dictionary holds all the 5-grams combinations with their counts\n",
    "        \"\"\"\n",
    "    Total_Count = 0\n",
    "    # Construct a default dictionary to save the fourgrams\n",
    "    Fivegrams_dict = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    # Loop for each line in the dataset\n",
    "    for line in Dataset:\n",
    "        #line.replace(' ','')\n",
    "        # Convert a string line to list of fourgrams (each four consecutive words)\n",
    "        list_of_grams = Fivegram(line)\n",
    "        Total_Count += len(list_of_grams)\n",
    "        # Fill the fourgrams dictionary with its keys and values\n",
    "        for w1,w2,w3,w4,w5 in list_of_grams:\n",
    "               Fivegrams_dict[(w1, w2, w3, w4)][w5] += 1\n",
    "    #Normailzation             \n",
    "    for w1_w2_w3_w4 in Fivegrams_dict:\n",
    "          for w5 in Fivegrams_dict[w1_w2_w3_w4]:\n",
    "                  Fivegrams_dict[w1_w2_w3_w4][w5] /=  Total_Count\n",
    "        \n",
    "    return Fivegrams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence5(fivegrams,sentence_,first_word, second_word, third_word, forth_word,iters=0,MAX_ITER=18):\n",
    "    #if forth_word == '.':\n",
    "        #return sentence\n",
    "    if iters >= MAX_ITER:\n",
    "        return sentence_\n",
    "    #next_word = max(fivegrams[first_word,second_word,third_word,forth_word], key=fivegrams[first_word,second_word,third_word,forth_word].get)\n",
    "    next_word = random.choice(list(fivegrams[first_word,second_word,third_word,forth_word].keys()))\n",
    "    sentence_.append(next_word)\n",
    "    return generate_sentence5(fivegrams=fivegrams,sentence_=sentence_,first_word = second_word, second_word=third_word, third_word=forth_word, forth_word=next_word, iters = iters+1, MAX_ITER=MAX_ITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fivegram TRIAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the fivegrams dictionary using the dataset available.\n",
    "fivegrams = construct_fivegrams(Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct 3 sentences using the fivegram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "even if you 've got one foot in the grave and its the only book you 're likely to \n",
      "\n",
      "even if you 've never climbed Mount Everest or gone sky diving . What 's far more important is \n",
      "\n",
      "even if you 've never met the person . I know you 're not supposed to judge a book \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters Definitions..\n",
    "max_iters = 15\n",
    "\n",
    "#Sentence 0\n",
    "sentence = ['even', 'if', 'you' , '\\'ve']\n",
    "sentence0 = generate_sentence5(fivegrams,sentence,first_word=sentence[0],second_word=sentence[1],third_word=sentence[2],forth_word=sentence[3],MAX_ITER=max_iters)\n",
    "print(' '.join(sentence0), '\\n')\n",
    "\n",
    "#Sentence 1\n",
    "sentence = ['even', 'if', 'you'  , '\\'ve']\n",
    "sentence1 = generate_sentence5(fivegrams,sentence,first_word=sentence[0],second_word=sentence[1],third_word=sentence[2],forth_word=sentence[3],MAX_ITER=max_iters)\n",
    "print(' '.join(sentence1), '\\n')\n",
    "\n",
    "#Sentence 2\n",
    "sentence = ['even', 'if', 'you'  , '\\'ve']\n",
    "sentence2 = generate_sentence5(fivegrams,sentence,first_word=sentence[0],second_word=sentence[1],third_word=sentence[2],forth_word=sentence[3],MAX_ITER=max_iters)\n",
    "print(' '.join(sentence2), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The sentences created using the 5-grams are slightly more sensible than those created using the 4-grams. However, for me, the biggest differnce appeared in the variablity in both methods. The variability in 4-gram is higher as there're more options. In other words, if we increase the number of created sentences, it would be much more likely for 5-grams model to repeate one of more or the sentences.** "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Language Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
